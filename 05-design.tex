\chapter{Design}
\label{Design}
This chapter describes the proposed design of the whole system for storing and exploring blockchains in IPFS that is to be created as a result of this thesis. All parts of the system are described in this chapter.

\section{Database system}
We need a database in our system to store and index data. Database system needs to be decentralized and distributed. There are several databases build on top of IPFS already implemented. The two most known are OrbitDB and Textile.

\subsection{OrbitDB}
OrbitDB is a serverless, distributed, peer-to-peer database build on top of IPFS, developed by HAJA networks. OrbitDB is a decent solution for small user's databases, but it is still in the alpha stage of developing, and it is not well optimized to store hundreds of gigabytes of data. The biggest problem is that OrbitDB performs all queries locally. To perform a query that selects transactions that are more valuable than 1BTC, OrbitDB needs to load the whole database locally and then perform a cycle on all transactions to selects only those transactions that meet the criteria. So every client ends up with a full copy of the database. This limitation is not usable for our case when we have a database that has hundreds of gigabytes of data.

\subsection{Textile}
Textile is a set of open-source tools that provide a distributed peer-to-peer database, remote storage, user management, and more, over the IPFS network. Textile already created applications for storing photos, notes or anything else (Anytype). Textile provides a high abstraction on top of the IPFS and provides simple API to store and index files securely. It uses Cafe peers to provides backups and indexing. Data are duplicated on several Cafe peers. When a client is performing some query, it contacts one of the Cafe peers to resolve the query for the client.
Neither of these solutions fits our use case to store a large amount of data distributed on several nodes and performs queries that can be resolved by downloading only necessary parts of the database. Therefore, we need to create a new database system based on IFPS that would be decentralized and distributed.

\subsection{Database system design}
After some research, we concluded that currently for storing and indexing data in IPFS without large harddisk memory consumption, there is no solution. We created our own indexing system that currently supports three types of indexes. A database system that fits our needs is distributed and decentralized. That brings us lots of synchronization problems to solve. This database system consists of tables that contain records. For faster searching, tables have indexes. Relations between tables are represented via foreign keys. Also, this database system supports fluent query language, used for performing complex queries.

\subsubsection{Record} 
Every record in our database system is stored in an append-only log that contains the whole history of the record. Every update of a record adds a new entry to its log which points to the previous entry. 

In centralized systems such as git, conflicts are detected on write (for example, when two git users push changes to the server at the same time, one of them gets an error and needs to pull repository). This approach is impossible in a decentralized system. When we update some record in our database, we can not know if somebody does not update it before (and we do not receive changes yet). For this reason, we need to solve conflicts while reading. Record with conflict has more than one head in a record log, and users need to solve them in application logic. Look at the example in Figure \ref{recordConflict}. There is a record that is updated by every country in the World when they have new statistics about a pandemic. It two countries updates data at the same time (their updates pointing to the same previous version of the entry) they create conflict. Luckily, this specific conflict is easy to solve. We just needs to look at the previous entry and compute increment for both country. Then update the record with final increment.


\begin{figure}[h]
    \centering
    \includegraphics[width=11cm]{recordConflictSolver.png}
    \caption{Record conflict}
    \label{recordConflict}
\end{figure}


\subsubsection{Indexes}
An index is B-tree optimized for IPFS (no cycled references and node size less than 256kB). Each table has at least one primary index. We use the primary index to reference record in foreign keys. A primary key is automatically created when a user does not specify it and has type of Guid. Value of the primary key for an entity can not be changed (because we would need to scan all tables where the entity is referenced and change the referenced value to a new one). Also, when we execute a query without any condition or sorting, we use a primary key to obtain records. Every index has several components: 
\begin{itemize}
    \item \textbf{Comparator} - is a function that has two parameters (two keys of B-tree) and outputs a number. An index is using a comparator to search records and insert record to the right place in B-tree.
    \item \textbf{Key-getter} - is a function that returns a comparable object from the record (a comparable object is an object that can be compared using index comparator). Every index has key-getter that is using to obtain keys for B-tree.
\end{itemize}

\subsubsection{Table}
A table contains indexes and table name. Also it implements operations like \texttt{insert}, \texttt{update} and \texttt{delete}.

\subsubsection{Foreign keys}
We use foreign keys to represent relationships between tables. A foreign key is simply a table name and a value of a primary key of a referenced record.

\subsubsection{Transactions}
When we commit a transaction, it is inserted to the transactions queue. If there are more transactions in the queue, a database performs it one by one. We can not execute more transactions in one moment, because it could cause data inconsistency. There are five types of transactions:
\begin{itemize}
    \item \texttt{read} - transaction for reading data from table. It is not logged in a database log (other peers don't have to know what we are reading from database).
    \item \texttt{sync} - when some peer publishes a new version of the database, all other peers have to migrate to it. This transaction has the biggest priority, and therefore it is inserted at the beginning of the transactions queue. After a migration is done, transactions queue can continue working normally.
    \item \texttt{insert}, \texttt{update}, \texttt{delete} - other types of transactions are written to database logs, because they are modifying the database.
\end{itemize}

\subsubsection{Synchronization} 
Every time a transaction queue is empty (all pending transactions has been applied), a new version of a database is broadcasted to all connected users. When we receive information about the new database version, we load its root. Each database version has information from which version was created. Database versions create an append-only log called database log. Database log is an immutable, operation-based conflict-free replicated data structure (CRDT\footnote{\url{https://en.wikipedia.org/wiki/Conflict-free_replicated_data_type}}) for storing database versions. Every version in the log is saved in IPFS and each points to a hash of previous version(s) forming a graph. Database logs can be forked and joined back together.\cite{crdtLog}

If more than one peer publishes a new version of the database that has been created from the same database version, other peers needs to decide which version they would accept. Opposite to records conflicts, we needs to solve database versions conflict fast and automatically. There are multiple ways to solve them. For example: 
\begin{itemize}
    \item \textbf{The biggest hash wins} - if there is more than one database version at the same (discrete) time, the one with the biggest hash wins. This strategy is present in Figure \ref{databaseConflict}. 
    \item \textbf{The longest connecting time wins} - a user who is connected to the database for the longest time wins.
\end{itemize}
Lots of more strategies can be implemented. But they need to be deterministic and as fair as possible. If we have access to geolocation, we can implement a strategy based on a distance to the North pole (the closest node to the North pole wins).

\begin{figure}[h]
    \centering
    \includegraphics[width=13cm]{DBconflict.png}
    \caption{Synchronization of a database. Note that in time 4, Node1 add two transactions in one DB version.}
    \label{databaseConflict}
\end{figure}

\subsubsection{Queries} 
A Database system provides query language for performing selects. A query consists of:
\begin{itemize}
    \item \textbf{conditions} - query may contains multiple conditions. There are logical operators (and - conjunction, or - disjunction) between conditions. When it is possible (an index is available on condition property), we use indexes for evaluating conditions. If there are more than one conditions, we use an intersection between and's conditions and union between or's a disjunction. These types of conditions are supported:
    \begin{itemize}
        \item \textbf{equal} - record property equals to specified value,
        \item \textbf{greather than} - record property is greather than specified value,
        \item \textbf{less than} - record property is less than specified value,
        \item \textbf{between} - record property is greather than specified minimal value, and less than specified maximal value.
    \end{itemize} 
    \item \textbf{filters} - filters are similar to conditions, but they can be more complicated. They are functions returning boolean that are being applied to query results. If any filter return \texttt{false} for the query result, the query result is ignored. A query can contain several filters.
    \item \textbf{offset} - offset saying how many query results should be ignored from the beginning.
    \item \textbf{evaluator} - we use evaluator for accessing results of the query.
    \begin{itemize}
        \item \textbf{all} - returns array of all results of the query,
        \item \textbf{first} - returns only first result,
        \item \textbf{take} - returns \texttt{N} number of results where \texttt{N} is an argument,
        \item \textbf{paginate} - returns page of results. Accept two arguments. \texttt{perPage} specifies the number of results in one page. \texttt{page} is number of requested page.
        \item \textbf{iterate} - returns iterator that can be used in cycles such as \texttt{for} or \texttt{while}.
    \end{itemize}
\end{itemize}  

\section{System components}
The system consists of one or more Feeders and Explorers. Feeders are connected to data sources and provide synchronization with cryptocurrency blockchains. Explorer can request data from the system network and display them to a user (see Figure \ref{systemArchitecture}).

\begin{figure}[h]
    \centering
    \includegraphics[width=11cm]{AppArchitecture.png}
    \caption{System architecture}
    \label{systemArchitecture}
\end{figure}

\subsection{Database design}
\label{design}

\begin{figure}[h]
    \centering
    \includegraphics[width=\textwidth]{ER.png}
    \caption{Entity-relationships diagram}
    \label{er}
\end{figure}

Both, Explorer and Feeder uses same database schema. The database schema is designed in the way to optimalize typical queries. It consists of five tables:
\begin{itemize}
    \item \textbf{Block} - table for storing blockchain blocks. It has a primary key on unique block hash, and indexes on height and time. With these indexes we can perform queries like search block by its hash or heigh very efficiently. Also filtering or ordering blocks by time has good performance.
    \item \textbf{Transaction} - a table that contains blockchain transactions has a primary key on transaction hash and foreign key, that references block in which is transaction confirmed, on \texttt{blockHash} column. Indexes for efficient filtering are on \texttt{blockHeight} and \texttt{blockTime} columns. 
    \item \textbf{Vin} - every transactions can have multiple inputs. These inputs are stored in Vin table. Every Vin has not got any unique property, so a custom Guid\footnote{\url{https://en.wikipedia.org/wiki/Universally_unique_identifier}} needs to be created as a primary key. It has two foreign keys to reference transaction and address. Foreign key \texttt{address} can be null, because an input can mined block reward.
    \item \textbf{Vout} - transactions can have multiple outputs. Every output has a foreign key to transaction and address. If an output is already spent, it has a link to the transaction where this output is used as an input.
    \item \textbf{Address} - Adress contains multiple columns. As primary key it uses address's hash. Address also contains its \texttt{balance}, \texttt{totalReceived} and \texttt{totalSent}. These values are updated every time new input or output is added to the transaction.  
\end{itemize}



\subsection{Feeder}
A Feeder is a service that stores data in IPFS and indexes them in our database system. Once all blocks are indexed, Feeder waits for new blocks and is periodicly publishing most updated database version. This way new clients synchronize database more quickly. For optimalization purposes, Feeder is performing transactions in bulks. This means that Feeder is not publishing new version of the database every time it parsed block or transaction, but rather after it parsed transactions bulk which can consists of hundreds of transactions.  

A Feeder can use different sources for obtaining blockchains data. It can be connected directly to the blockchain as a full node or to some other data source providing blockchain data as Blockbook\footnote{\url{https://github.com/trezor/blockbook}} or Insight\footnote{\url{https://insight.is}}.


\subsection{Explorer}
Explorer can perform basic queries like a search for block by its height or hash and search address and transaction by hash. Nevertheless, Explorer can also make more complex queries for example, get the first 20 transaction where the sum of inputs is more than some value, or get transactions between some time interval. Explorer is an application that can be used in two environments. In browser with graphical user interface, or in node.js\footnote{\url{https://nodejs.org/}} as a RestAPI.

\subsubsection{ExplorerGUI}
ExplorerGUI is browser version of Explorer. It is implemented as a SPA\footnote{\url{https://en.wikipedia.org/wiki/Single-page_application}} to prevent restarting connection with IPFS after each time a user visit a different page. It has separated views for block, transaction and address details. Also paginating, filtering and sorting objects by all its properties that has index is supported. Every user of ExplorerGUI keeps part of the database that he use in his local storage. This principle helps balance Feeders load, and helps to distribute data for other users.  Authentication to the ExplorerGUI is not necessary, because users can not modify data from there. They can only explore multiple blockchain data. All views have the same top toolbar, to allow user performs quick searches. User can see enabled cryptocurrencies at the home screen (see Figure \ref{homeMockup}). When a user selects cryptocurrency that he wants to explore, he will be redirected to the Blocks view where he can see and filter all parsed blocks from a selected cryptocurrency (see Figure \ref{blocksMockup}). User can select block by clicking on them. This action redirect a user to Block detail view where he can see all blocks transactions (see Figure \ref{blockDetailMockup}). User can also navigate to the next/previous block from this view. A user gets to the Address view every time he clicks on transaction input or output address. In this view, a user can see the current balance of the address and transaction which this address was part of (see Figure \ref{addressMockup}). Thanks to the database design, a user can also see the history of the address. 


\begin{figure}[h]
    \begin{subfigure}{.5\textwidth}
        \centering
        \includegraphics[width=1.0\linewidth]{mockups/home.png}
        \caption{Home view}
        \label{homeMockup}
    \end{subfigure}
    \begin{subfigure}{.5\textwidth}
        \centering
        \includegraphics[width=1.0\linewidth]{mockups/blocks.png}
        \caption{Blocks list view}
        \label{blocksMockup}
    \end{subfigure}
    \begin{subfigure}{.5\textwidth}
        \centering
        \includegraphics[width=1.0\linewidth]{mockups/blockDetail.png}
        \caption{Block detail view}
        \label{blockDetailMockup}
    \end{subfigure}
    \begin{subfigure}{.5\textwidth}
        \centering
        \includegraphics[width=1.0\linewidth]{mockups/address.png}
        \caption{Address view}
        \label{addressMockup}
    \end{subfigure}
    \caption{ExplorerGUI mockups}
\end{figure}

\subsubsection{ExplorerAPI}
\label{explorerAPIroutes}
ExplorerAPI is a server-side application that provides simple RESTapi for obtaining data. It is much less demanding on performance than ExplorerGUI and can be used for integrations with other applications. It has several endpoints:
\begin{itemize}
    \item \texttt{GET /currency/[:currencyUnit]/tx/[:txHash]} - get transaction by hash,
    \item \texttt{GET /currency/[:currencyUnit]/block} - get block collection,
    \item \texttt{GET /currency/[:currencyUnit]/block/[:blockHeightOrHash]} - get block by height or hash,
    \item \texttt{GET /currency/[:currencyUnit]/address} - get address collection,
    \item \texttt{GET /currency/[:currencyUnit]/address/[:hash]} - get address by hash.
\end{itemize}

Every endpoint supports query parameters:
\begin{itemize}
    \item \texttt{filter} where value of this parameter can be simple arithmetic expression like \texttt{height>50},
    \item \texttt{limit} parameter for pagination with default value set to \texttt{20},
    \item \texttt{orderBy} sorts results of a sequence in ascending order.
    \item \todo{Paginate}
\end{itemize}
 



