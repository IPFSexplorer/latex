\chapter{Design}
\label{Design}
This chapter describes the proposed design of the whole system for storing and exploring blockchains in IPFS that is to be created as a result of this thesis. All parts of the system are described in this chapter.

\section{Database system}
We need a database in our system to store and index data. Database system needs to be decentralized and distributed. There are several databases build on top of IPFS already implemented. The two most known are OrbitDB and Textile.

\subsection{OrbitDB}
OrbitDB is a serverless, distributed, peer-to-peer database build on top of IPFS, developed by HAJA networks. OrbitDB is a decent solution for small user's databases, but it is still in the alpha stage of developing, and it is not well optimized to store hundreds of gigabytes of data. The biggest problem is that OrbitDB performs all queries locally. To perform a query that selects transactions that are more valuable than 1BTC, OrbitDB needs to load the whole database locally and then perform a cycle on all transactions to selects only those transactions that meet the criteria. So every client ends up with a full copy of the database. This limitation is not usable for our case when we have a database that has hundreds of gigabytes of data.

\subsection{Textile}
Textile is a set of open-source tools that provide a distributed peer-to-peer database, remote storage, user management, and more, over the IPFS network. Textile already created applications for storing photos, notes or anything else (Anytype). Textile provides a high abstraction on top of the IPFS and provides simple API to store and index files securely. It uses Cafe peers to provides backups and indexing. Data are duplicated on several Cafe peers. When a client is performing some query, it contacts one of the Cafe peers to resolve the query for the client.
Neither of these solutions fits our use case to store a large amount of data distributed on several nodes and performs queries that can be resolved by downloading only necessary parts of the database. Therefore, we need to create a new database system based on IFPS that would be decentralized and distributed.

\subsection{Database system design}
After some research, we concluded that currently for storing and indexing data in IPFS without large harddisk memory consumption, there is no solution. We created our own indexing system that currently supports three types of indexes. A database system that fits our needs is distributed and decentralized. That brings us lots of synchronization problems to solve. This database system consists of tables that contain records. For faster searching, tables have indexes. Relations between tables are represented via foreign keys. Also, this database system supports fluent query language, used for performing complex queries.

\subsubsection{Record} 
Every record in our database system is stored in an append-only log that contains the whole history of the record. Every update of a record adds a new entry to its log which points to the previous entry. 

In centralized systems such as git, conflicts are detected on write (for example, when two git users push changes to the server at the same time, one of them gets an error and needs to pull repository). This approach is impossible in a decentralized system. When we update some record in our database, we can not know if somebody does not update it before (and we do not receive changes yet). For this reason, we need to solve conflicts while reading. Record with conflict has more than one head in a record log, and users need to solve them in application logic. Look at the example in Figure \ref{recordConflict}. There is a record that is updated by every country in the World when they have new statistics about a pandemic. It two countries updates data at the same time (their updates pointing to the same previous version of the entry) they create conflict. Luckily, this specific conflict is easy to solve. We just needs to look at the previous entry and compute increment for both country. Then update the record with final increment.


\begin{figure}[h]
    \centering
    \includegraphics[width=11cm]{recordConflictSolver.png}
    \caption{Record conflict}
    \label{recordConflict}
\end{figure}


\subsubsection{Indexes}
An index is B-tree optimized for IPFS (no cycled references and node size less than 256kB). Each table has at least one primary index. Primary Index - We use the primary index to reference record in foreign keys. A primary key is automatically created when a user does not specify it. Value of the primary key for an entity can not be changed (because we would need to scan all tables where the entity is referenced and change the referenced value to a new one). Also, when we execute a query without any condition or sorting, we use a primary key to obtain records. Every index has several components: 
\begin{itemize}
    \item \textbf{Comparator} - is a function that has two parameters (two keys of B-tree) and outputs a number. An index is using a comparator to search records and insert record to the right place in B-tree.
    \item \textbf{Key-getter} - is a function that returns a comparable object from the record (a comparable object is an object that can be compared using index comparator). Every index has key-getter that is using to obtain keys for B-tree.
\end{itemize}

\subsubsection{Table}
A table contains indexes and table name. Also it implements operations like \texttt{insert}, \texttt{update} and \texttt{delete}.

\subsubsection{Foreign keys}
We use foreign keys to represent relationships between tables. A foreign key is simply a table name and a value of a primary key of a referenced record.

\subsubsection{Transactions}
When we commit a transaction, it is inserted to the transactions queue. If there are more transactions in the queue, a database performs it one by one. We can not execute more transactions in one moment, because it could cause data inconsistency. There are five types of transactions:
\begin{itemize}
    \item \texttt{read} - transaction for reading data from table. It is not logged in a database log (other peers don't have to know what we are reading from database).
    \item \texttt{sync} - when some peer publishes a new version of the database, all other peers have to migrate to it. This transaction has the biggest priority, and therefore it is inserted at the beginning of the transactions queue. After a migration is done, transactions queue can continue working normally.
    \item \texttt{insert}, \texttt{update}, \texttt{delete} - other types of transactions are written to database logs, because they are modifying the database.
\end{itemize}

\subsubsection{Synchronization} 
Every time a transaction queue is empty (all pending transactions has been applied), a new version of a database is broadcasted to all connected users. When we receive information about the new database version, we load its root. Each database version has information from which version was created. Database versions create an append-only log called database log. Database log is an immutable, operation-based conflict-free replicated data structure (CRDT\footnote{\url{https://en.wikipedia.org/wiki/Conflict-free_replicated_data_type}}) for storing database versions. Every version in the log is saved in IPFS and each points to a hash of previous version(s) forming a graph. Database logs can be forked and joined back together.\cite{crdtLog}

If more than one peer publishes a new version of the database that has been created from the same database version, other peers needs to decide which version they would accept. Opposite to records conflicts, we needs to solve database versions conflict fast and automatically. There are multiple ways to solve them. For example: 
\begin{itemize}
    \item \textbf{The biggest hash wins} - if there is more than one database version at the same (discrete) time, the one with the biggest hash wins. This strategy is present in Figure \ref{databaseConflict}. 
    \item \textbf{The longest connecting time wins} - a user who is connected to the database for the longest time wins.
\end{itemize}
Lots of more strategies can be implemented. But they need to be deterministic and as fair as possible. If we have access to geolocation, we can implement a strategy based on a distance to the North pole (the closest node to the North pole wins).

\begin{figure}[h]
    \centering
    \includegraphics[width=13cm]{DBconflict.png}
    \caption{Synchronization of a database. Note that in time 4, Node1 add two transactions in one DB version.}
    \label{databaseConflict}
\end{figure}

\subsubsection{Queries} 
A Database system provides query language for performing selects. A query consists of:
\begin{itemize}
    \item \textbf{conditions} - query may contains multiple conditions. There are logical operators (and - conjunction, or - disjunction) between conditions. When it is possible (an index is available on condition property), we use indexes for evaluating conditions. If there are more than one conditions, we use an intersection between and's conditions and union between or's a disjunction. These types of conditions are supported:
    \begin{itemize}
        \item \textbf{equal} - record property equals to specified value,
        \item \textbf{greather than} - record property is greather than specified value,
        \item \textbf{less than} - record property is less than specified value,
        \item \textbf{between} - record property is greather than specified minimal value, and less than specified maximal value.
    \end{itemize} 
    \item \textbf{filters} - filters are similar to conditions, but they can be more complicated. They are functions returning boolean that are being applied to query results. If any filter return \texttt{false} for the query result, the query result is ignored. A query can contain several filters.
    \item \textbf{offset} - offset saying how many query results should be ignored from the beginning.
    \item \textbf{evaluator} - we use evaluator for accessing results of the query.
    \begin{itemize}
        \item \textbf{all} - returns array of all results of the query,
        \item \textbf{first} - returns only first result,
        \item \textbf{take} - returns \texttt{N} number of results where \texttt{N} is an argument,
        \item \textbf{paginate} - returns page of results. Accept two arguments. \texttt{perPage} specifies the number of results in one page. \texttt{page} is number of requested page.
        \item \textbf{iterate} - returns iterator that can be used in cycles such as \texttt{for} or \texttt{while}.
    \end{itemize}
\end{itemize}  

\section{System components}
The system consists of one or more Feeders and Explorers. Feeders are connected to data sources and provide synchronization with cryptocurrency blockchains. Explorer can request data from the system network and display them to a user (see Figure \ref{systemArchitecture}).

\begin{figure}[h]
    \centering
    \includegraphics[width=11cm]{AppArchitecture.png}
    \caption{System architecture}
    \label{systemArchitecture}
\end{figure}


\section{Feeder}
A Feeder is a service that stores data in IPFS and indexes them in our database system. Feeder stores data in an acyclic structure (see Figure \ref{feederDataStorageStructure}). Every block has links to transactions that are confirmed in this block. An address also has links to all its transactions. This scheme allows storing blockchain data in IPFS in small objects with size less than 256kB (a limit for storing objects directly in DHT). Cyclic references (for example between next/previous blocks) are not possible, because links are changing CID of an object. Therefore if we store object \texttt{A} with a link to the object \texttt{B}, CID of \texttt{A} will change. Then if we add backlink from \texttt{B} to \texttt{A}, CID of \texttt{B} will be changed and so \texttt{A} has now link to an old version of \texttt{B}. If we update link of object \texttt{A} to point on the new version of object \texttt{B}, CID of object \texttt{A} will change and therefore object \texttt{B} is now pointing to the old version of object \texttt{A}. From this example, it appears that there is no way of making cyclic references in IPFS.

A Feeder can use different sources for obtaining blockchains data. It can be connected directly to the blockchain as a full node or to some other data source providing blockchain data as Blockbook\footnote{\url{https://github.com/trezor/blockbook}} or Insight\footnote{\url{https://insight.is}}.


\todo{Describe used indexes and database structure that is present in feeder}


% \begin{figure}[h]
%     \centering
%     \includegraphics[width=12cm]{feederDataStorageStructure.png}
%     \caption{Feeder data storage structure}
%     \label{feederDataStorageStructure}
%     \todo{change image to represent real scheme described}
% \end{figure}



\section{Explorer}
Explorer can perform basic queries like a search for block by its height or hash and search address and transaction by hash. Nevertheless, Explorer can also make more complex queries for example, get the first 20 transaction where the sum of inputs is more than some value, or get transactions between some time interval. Explorer is an application that can be used in two environments. In browser with graphical user interface, or in node.js\footnote{\url{https://nodejs.org/}} as a RestAPI.

\subsection{ExplorerGUI}
ExplorerGUI is browser version of Explorer. It is implemented as a SPA\footnote{\url{https://en.wikipedia.org/wiki/Single-page_application}} to prevent restarting connection with IPFS after each time a user visit different page. It has separated views for block, transaction and address details. Also paginating, filtering and sorting objects by all its properties is supported.


\subsection{ExplorerAPI}
\label{explorerAPIroutes}
ExplorerAPI is a node.js application provides several endpoints for obtaining the data:
\begin{itemize}
    \item \texttt{GET /tx} - get collection of transaction, 
    \item \texttt{GET /tx/[:txHash]} - get transaction by hash,
    \item \texttt{GET /block} - get block collection,
    \item \texttt{GET /block/[:blockHeightOrHash]} - get block by height or hash,
    \item \texttt{GET /address} - get address collection,
    \item \texttt{GET /address/[:hash]} - get address by hash.
\end{itemize}
All endpoints support more detailed path specification by providing multiple parameters at the end of the path (for example, it is possible to request only a block hash by calling \texttt{/block/42/hash}). Also, every endpoint supports query parameters
\begin{itemize}
    \item \texttt{filter} where value of this parameter can be simple arithmetic expression like \texttt{height>50},
    \item \texttt{limit} parameter for pagination with default value set to \texttt{20},
    \item \texttt{orderBy} sorts results of a sequence in ascending order.
\end{itemize}
 



